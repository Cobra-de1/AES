{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Federated_Privacy_AutoEncoder.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOgJxwwbjpmaS6bd1ZREghx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Cobra-de1/AES/blob/main/Federated_Privacy_AutoEncoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CYCgesqroKs"
      },
      "source": [
        "!git clone https://github.com/fastforwardlabs/deepad.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNmQfBEgCfEZ"
      },
      "source": [
        "!pip3 install git+https://github.com/fastforwardlabs/cmlbootstrap#egg=cmlbootstrap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dxndmlsKSd1"
      },
      "source": [
        "!pip3 install tensorflow-privacy\n",
        "!pip3 install syft-tensorflow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCAVVNfi4R9Z"
      },
      "source": [
        "!pip3 install syft[tensor-flow]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yl6Ly-f0sxIk"
      },
      "source": [
        "import os\n",
        "os.chdir('deepad')\n",
        "\n",
        "import argparse\n",
        "from deepad.utils import data_utils, eval_utils\n",
        "import numpy as np\n",
        "\n",
        "import logging\n",
        "logging.basicConfig(level=logging.INFO)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqqrfGKMcXz8"
      },
      "source": [
        "import tensorflow\n",
        "from tensorflow.keras.layers import Lambda, Input, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.losses import mse\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras import regularizers\n",
        "import logging\n",
        "\n",
        "from tensorflow_privacy.privacy.analysis.rdp_accountant import compute_rdp\n",
        "from tensorflow_privacy.privacy.analysis.rdp_accountant import get_privacy_spent\n",
        "from tensorflow_privacy.privacy.optimizers.dp_optimizer_keras import DPKerasAdamOptimizer\n",
        "\n",
        "import os\n",
        "from deepad.utils import train_utils\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "\n",
        "# set random seed for reproducibility\n",
        "tensorflow.random.set_seed(2018)\n",
        "np.random.seed(2018)\n",
        "np.random.RandomState(2018)\n",
        "random.seed(2018)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjJwWbmhbnQD"
      },
      "source": [
        "class AutoencoderModel():\n",
        "\n",
        "    def __init__(self, n_features, hidden_layers=2, latent_dim=2, hidden_dim=[15, 7],\n",
        "                 output_activation='sigmoid', learning_rate=0.01, epochs=15, batch_size=128, model_path=None):\n",
        "        \"\"\" Build AE model.\n",
        "        Arguments:\n",
        "            - n_features (int): number of features in the data\n",
        "            - hidden_layers (int): number of hidden layers used in encoder/decoder\n",
        "            - latent_dim (int): dimension of latent variable\n",
        "            - hidden_dim (list): list with dimension of each hidden layer\n",
        "            - output_activation (str): activation type for last dense layer in the decoder\n",
        "            - learning_rate (float): learning rate used during training\n",
        "        \"\"\"\n",
        "\n",
        "        self.epochs = epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.model_name = \"ae\"\n",
        "\n",
        "        self.create_model(n_features, hidden_layers=hidden_layers, latent_dim=latent_dim,\n",
        "                          hidden_dim=hidden_dim, output_activation=output_activation,\n",
        "                          learning_rate=learning_rate, model_path=model_path)\n",
        "\n",
        "    def create_model(self, n_features, hidden_layers=1, latent_dim=2, hidden_dim=[],\n",
        "                     output_activation='sigmoid', learning_rate=0.001, model_path=None):\n",
        "\n",
        "        # set dimensions hidden layers\n",
        "        if hidden_dim == []:\n",
        "            i = 0\n",
        "            dim = n_features\n",
        "            while i < hidden_layers:\n",
        "                hidden_dim.append(int(np.max([dim/2, 2])))\n",
        "                dim /= 2\n",
        "                i += 1\n",
        "\n",
        "        # Optional: add regularization to minimize overfitting?\n",
        "        # kernel_regularizer = regularizers.l1_l2(l1=0.01, l2=0.01)\n",
        "        # kernel_regularizer = regularizers.l1(0.01)\n",
        "        kernel_regularizer = None\n",
        "\n",
        "        # AE = encoder + decoder\n",
        "        # encoder\n",
        "        inputs = Input(shape=(n_features,), name='encoder_input')\n",
        "        # define hidden layers\n",
        "        enc_hidden = Dense(hidden_dim[0], activation='relu', name='encoder_hidden_0',\n",
        "                           kernel_regularizer=kernel_regularizer)(inputs)\n",
        "        i = 1\n",
        "        while i < hidden_layers:\n",
        "            enc_hidden = Dense(hidden_dim[i], activation='relu', name='encoder_hidden_'+str(\n",
        "                i), kernel_regularizer=kernel_regularizer)(enc_hidden)\n",
        "            i += 1\n",
        "\n",
        "        z_ = Dense(latent_dim, name='z_')(enc_hidden)\n",
        "\n",
        "        encoder = Model(inputs, z_, name='encoder')\n",
        "        logging.info(encoder.summary())\n",
        "        # plot_model(encoder, to_file='ae_mlp_encoder.png',\n",
        "        #            show_shapes=True)\n",
        "\n",
        "        # decoder\n",
        "        latent_inputs = Input(shape=(latent_dim,), name='z_')\n",
        "        # define hidden layers\n",
        "        dec_hidden = Dense(hidden_dim[-1], activation='relu', name='decoder_hidden_0',\n",
        "                           kernel_regularizer=kernel_regularizer)(latent_inputs)\n",
        "\n",
        "        i = 2\n",
        "        while i < hidden_layers+1:\n",
        "            dec_hidden = Dense(hidden_dim[-i], activation='relu', name='decoder_hidden_'+str(\n",
        "                i-1), kernel_regularizer=kernel_regularizer)(dec_hidden)\n",
        "            i += 1\n",
        "\n",
        "        outputs = Dense(n_features, activation=output_activation,\n",
        "                        name='decoder_output')(dec_hidden)\n",
        "        # instantiate decoder model\n",
        "        decoder = Model(latent_inputs, outputs, name='decoder')\n",
        "        logging.info(decoder.summary())\n",
        "        # plot_model(decoder, to_file='ae_mlp_decoder.png',\n",
        "        #            show_shapes=True)\n",
        "\n",
        "        # instantiate AE model\n",
        "        outputs = decoder(encoder(inputs))\n",
        "        self.model = Model(inputs, outputs, name='ae', )\n",
        "\n",
        "        # Differential privacy parameters\n",
        "        l2_norm_clip = 1.5\n",
        "        noise_multiplier = 0.5  # more noise -> more privacy, less utility\n",
        "        num_microbatches = 1  # how many batches to split a batch into\n",
        "\n",
        "        optimizer = DPKerasAdamOptimizer(\n",
        "            l2_norm_clip=l2_norm_clip,\n",
        "            noise_multiplier=noise_multiplier,\n",
        "            num_microbatches=num_microbatches,\n",
        "            learning_rate=learning_rate)\n",
        "        \n",
        "        #optimizer = Adam(lr=learning_rate)\n",
        "        \n",
        "        self.model.compile(optimizer=optimizer, loss=\"mse\")\n",
        "\n",
        "    def train(self, in_train, in_val):\n",
        "        # default args\n",
        "\n",
        "        # training\n",
        "\n",
        "        X_train, X_val = in_train, in_val\n",
        "        logging.info(\"Training with data of shape \" + str(X_train.shape))\n",
        "\n",
        "        kwargs = {}\n",
        "        kwargs['epochs'] = self.epochs\n",
        "        kwargs['batch_size'] = self.batch_size\n",
        "        kwargs['shuffle'] = True\n",
        "        kwargs['validation_data'] = (X_val, X_val)\n",
        "        kwargs['verbose'] = 1\n",
        "        kwargs['callbacks'] = [train_utils.TimeHistory()]\n",
        "\n",
        "        history = self.model.fit(X_train, X_train, **kwargs)\n",
        "\n",
        "    def compute_anomaly_score(self, df):\n",
        "        preds = self.model.predict(df)\n",
        "        mse = np.mean(np.power(df - preds, 2), axis=1)\n",
        "        return mse\n",
        "\n",
        "    def save_model(self, model_path=\"models/savedmodels/ae/\"):\n",
        "        logging.info(\">> Saving AE model to \" + model_path)\n",
        "        self.model.save_weights(model_path + \"model\")\n",
        "\n",
        "    def load_model(self, model_path=\"models/savedmodels/ae/\"):\n",
        "        if (os.path.exists(model_path)):\n",
        "            logging.info(\">> Loading saved model weights\")\n",
        "            self.model.load_weights(model_path + \"model\")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HStWcl3VtHJt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f678c35-8354-4f2c-ae55-ee2d13e33656"
      },
      "source": [
        "test_data_partition = \"8020\"\n",
        "in_train, out_train, scaler, _ = data_utils.load_kdd(\n",
        "    data_path=\"data/kdd/\", dataset_type=\"train\", partition=test_data_partition)\n",
        "in_test, out_test, _, _ = data_utils.load_kdd(\n",
        "    data_path=\"data/kdd/\", dataset_type=\"test\", partition=test_data_partition, scaler=scaler)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:root: >> KDD dataset loaded\n",
            "INFO:root: >> KDD dataset loaded\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mXRAKzGtPDF"
      },
      "source": [
        "def train_autoencoder():\n",
        "    # Instantiate and Train Autoencoder\n",
        "    ae_kwargs = {}\n",
        "    ae_kwargs[\"latent_dim\"] = 2\n",
        "    ae_kwargs[\"hidden_dim\"] = [15, 7]\n",
        "    ae_kwargs[\"epochs\"] = 14\n",
        "    ae_kwargs[\"batch_size\"] = 128\n",
        "    # ae_kwargs[\"model_path\"] = ae_model_path\n",
        "    ae = AutoencoderModel(in_train.shape[1], **ae_kwargs)\n",
        "    ae.train(in_train, in_test)\n",
        "    ae.save_model()\n",
        "\n",
        "    inlier_scores = ae.compute_anomaly_score(in_test)\n",
        "    outlier_scores = ae.compute_anomaly_score(out_test)\n",
        "    print(inlier_scores)\n",
        "    print(outlier_scores)\n",
        "    metrics = eval_utils.evaluate_model(\n",
        "        inlier_scores, outlier_scores, model_name=\"ae\", show_plot=False)\n",
        "    print(metrics)\n",
        "    return metrics"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEvgwFFOBTUo",
        "outputId": "bb4a7ab6-5570-4ebe-c2b2-f9b3a69e7fc9"
      },
      "source": [
        "train_autoencoder()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:root:None\n",
            "INFO:root:None\n",
            "INFO:root:Training with data of shape (97278, 18)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"encoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "encoder_input (InputLayer)   [(None, 18)]              0         \n",
            "_________________________________________________________________\n",
            "encoder_hidden_0 (Dense)     (None, 15)                285       \n",
            "_________________________________________________________________\n",
            "encoder_hidden_1 (Dense)     (None, 7)                 112       \n",
            "_________________________________________________________________\n",
            "z_ (Dense)                   (None, 2)                 16        \n",
            "=================================================================\n",
            "Total params: 413\n",
            "Trainable params: 413\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "z_ (InputLayer)              [(None, 2)]               0         \n",
            "_________________________________________________________________\n",
            "decoder_hidden_0 (Dense)     (None, 7)                 21        \n",
            "_________________________________________________________________\n",
            "decoder_hidden_1 (Dense)     (None, 15)                120       \n",
            "_________________________________________________________________\n",
            "decoder_output (Dense)       (None, 18)                288       \n",
            "=================================================================\n",
            "Total params: 429\n",
            "Trainable params: 429\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/14\n",
            "760/760 [==============================] - 5s 3ms/step - loss: 0.2094 - val_loss: 0.1787\n",
            "Epoch 2/14\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 0.1537 - val_loss: 0.1330\n",
            "Epoch 3/14\n",
            "760/760 [==============================] - 2s 2ms/step - loss: 0.1110 - val_loss: 0.0918\n",
            "Epoch 4/14\n",
            "760/760 [==============================] - 2s 2ms/step - loss: 0.0844 - val_loss: 0.0595\n",
            "Epoch 5/14\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 0.0714 - val_loss: 0.0494\n",
            "Epoch 6/14\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 0.0798 - val_loss: 0.0788\n",
            "Epoch 7/14\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 0.0700 - val_loss: 0.0380\n",
            "Epoch 8/14\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 0.0585 - val_loss: 0.0394\n",
            "Epoch 9/14\n",
            "760/760 [==============================] - 2s 2ms/step - loss: 0.0599 - val_loss: 0.0414\n",
            "Epoch 10/14\n",
            "760/760 [==============================] - 2s 2ms/step - loss: 0.0605 - val_loss: 0.0460\n",
            "Epoch 11/14\n",
            "760/760 [==============================] - 2s 2ms/step - loss: 0.0603 - val_loss: 0.0330\n",
            "Epoch 12/14\n",
            "760/760 [==============================] - 2s 2ms/step - loss: 0.0590 - val_loss: 0.0317\n",
            "Epoch 13/14\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 0.0572 - val_loss: 0.0328\n",
            "Epoch 14/14\n",
            "760/760 [==============================] - 2s 3ms/step - loss: 0.0595 - val_loss: 0.0361\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:root:>> Saving AE model to models/savedmodels/ae/\n",
            "INFO:root:4693unique thresholds\n",
            "INFO:root:Testing all thresholds to find best accuracy ...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[0.36571972 0.36151761 0.01650999 ... 0.10743056 0.09246905 0.00062915]\n",
            "[0.3918786  0.16342898 0.16342898 ... 0.11322385 0.11336261 0.16342898]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:root:Threshold testing complete ...\n",
            "INFO:root:Best accuracy is .. {'acc': 0.9481, 'threshold': 0.113}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'acc': 0.945, 'precision': 0.8059071729957806, 'recall': 0.955, 'f1': 0.8741418764302059, 'f2': 0.9209257473481195, 'roc': 0.9608531875, 'threshold': 0.113}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'acc': 0.945,\n",
              " 'f1': 0.8741418764302059,\n",
              " 'f2': 0.9209257473481195,\n",
              " 'precision': 0.8059071729957806,\n",
              " 'recall': 0.955,\n",
              " 'roc': 0.9608531875,\n",
              " 'threshold': 0.113}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2n8bHcONKyk"
      },
      "source": [
        "'''\n",
        "import syft as sy\n",
        "\n",
        "hook = sy.KerasHook(tf)\n",
        "alice = sy.VirtualWorker(hook, id=\"alice\")\n",
        "bob = sy.VirtualWorker(hook, id=\"bob\")\n",
        "workers = [alice, bob]\n",
        "\n",
        "# this is done to have the local worker (you on your notebook!) have a registry\n",
        "# of objects like every other workers, which is disabled by default but needed here\n",
        "sy.local_worker.is_client_worker = False\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLcaaZTNdfeT"
      },
      "source": [
        "workers = ['alice', 'bob']"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0ZkRwYcXQOx"
      },
      "source": [
        "def make_model(inputshape):\n",
        "    ae_kwargs = {}\n",
        "    ae_kwargs[\"latent_dim\"] = 2\n",
        "    ae_kwargs[\"hidden_dim\"] = [15, 7]\n",
        "    ae_kwargs[\"epochs\"] = 14\n",
        "    ae_kwargs[\"batch_size\"] = 128\n",
        "    # ae_kwargs[\"model_path\"] = ae_model_path\n",
        "    return AutoencoderModel(inputshape, **ae_kwargs)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUKL-t_fnwBs"
      },
      "source": [
        "def federate(data, workers):\n",
        "  number_worker = len(workers)\n",
        "  federated = []\n",
        "  offset = len(data) // number_worker\n",
        "  for i in range(number_worker):\n",
        "    federated.append(data[offset * i:offset * (i + 1)])\n",
        "  return np.array(federated)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvXJNn_CuY23"
      },
      "source": [
        "'''\n",
        "def send_new_models(local_model, models):\n",
        "    with th.no_grad():\n",
        "        for remote_model in models:\n",
        "            for new_param, remote_param in zip(local_model.parameters(), remote_model.parameters()):\n",
        "                worker = remote_param.location\n",
        "                remote_value = new_param.send(worker)\n",
        "                remote_param.set_(remote_value)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsBi9ENjPaPY"
      },
      "source": [
        "def send_new_models(local_model, models):\n",
        "  for i, worker in enumerate(workers):\n",
        "    new_param = local_model.model.get_weights()\n",
        "    models[i].model.set_weights(new_param)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_y-HUe4uZTW"
      },
      "source": [
        "'''\n",
        "def federated_aggregation(local_model, models):\n",
        "    with th.no_grad():\n",
        "        for local_param, *remote_params in zip(*([local_model.parameters()] + [model.parameters() for model in models])):\n",
        "            param_stack = th.zeros(*remote_params[0].shape)\n",
        "            for remote_param in remote_params:\n",
        "                param_stack += remote_param.copy().get()\n",
        "            param_stack /= len(remote_params)\n",
        "            local_param.set_(param_stack)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZgbizWrQZRx"
      },
      "source": [
        "def federated_aggregation(local_model, models):  \n",
        "  for i, worker in enumerate(workers):\n",
        "    if i == 0:\n",
        "      local_param = models[i].model.get_weights()\n",
        "    else:\n",
        "      for index in range(len(local_param)):\n",
        "        local_param[index] += models[i].model.get_weights()[index]\n",
        "  for i in range(len(local_param)):\n",
        "    local_param[i] = local_param[i] / len(workers)\n",
        "  local_model.model.set_weights(local_param)  "
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-25xaAtzxWb"
      },
      "source": [
        "save_in_train = in_train.copy()\n",
        "save_in_test = in_test.copy()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-N-OQlMquvJx"
      },
      "source": [
        "in_train = federate(in_train, workers)\n",
        "in_test = federate(in_test, workers)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSQc_-Oht7w-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc65ba55-5c48-4927-90fd-3196dee99bd8"
      },
      "source": [
        "local_model = make_model(in_train[0].shape[1])\n",
        "models = []\n",
        "for i in range(len(workers)):\n",
        "    model = make_model(in_train[0].shape[1])\n",
        "    models.append(model)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:root:None\n",
            "INFO:root:None\n",
            "INFO:root:None\n",
            "INFO:root:None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"encoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "encoder_input (InputLayer)   [(None, 18)]              0         \n",
            "_________________________________________________________________\n",
            "encoder_hidden_0 (Dense)     (None, 15)                285       \n",
            "_________________________________________________________________\n",
            "encoder_hidden_1 (Dense)     (None, 7)                 112       \n",
            "_________________________________________________________________\n",
            "z_ (Dense)                   (None, 2)                 16        \n",
            "=================================================================\n",
            "Total params: 413\n",
            "Trainable params: 413\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "z_ (InputLayer)              [(None, 2)]               0         \n",
            "_________________________________________________________________\n",
            "decoder_hidden_0 (Dense)     (None, 7)                 21        \n",
            "_________________________________________________________________\n",
            "decoder_hidden_1 (Dense)     (None, 15)                120       \n",
            "_________________________________________________________________\n",
            "decoder_output (Dense)       (None, 18)                288       \n",
            "=================================================================\n",
            "Total params: 429\n",
            "Trainable params: 429\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"encoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "encoder_input (InputLayer)   [(None, 18)]              0         \n",
            "_________________________________________________________________\n",
            "encoder_hidden_0 (Dense)     (None, 15)                285       \n",
            "_________________________________________________________________\n",
            "encoder_hidden_1 (Dense)     (None, 7)                 112       \n",
            "_________________________________________________________________\n",
            "z_ (Dense)                   (None, 2)                 16        \n",
            "=================================================================\n",
            "Total params: 413\n",
            "Trainable params: 413\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "z_ (InputLayer)              [(None, 2)]               0         \n",
            "_________________________________________________________________\n",
            "decoder_hidden_0 (Dense)     (None, 7)                 21        \n",
            "_________________________________________________________________\n",
            "decoder_hidden_1 (Dense)     (None, 15)                120       \n",
            "_________________________________________________________________\n",
            "decoder_output (Dense)       (None, 18)                288       \n",
            "=================================================================\n",
            "Total params: 429\n",
            "Trainable params: 429\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:root:None\n",
            "INFO:root:None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"encoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "encoder_input (InputLayer)   [(None, 18)]              0         \n",
            "_________________________________________________________________\n",
            "encoder_hidden_0 (Dense)     (None, 15)                285       \n",
            "_________________________________________________________________\n",
            "encoder_hidden_1 (Dense)     (None, 7)                 112       \n",
            "_________________________________________________________________\n",
            "z_ (Dense)                   (None, 2)                 16        \n",
            "=================================================================\n",
            "Total params: 413\n",
            "Trainable params: 413\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "z_ (InputLayer)              [(None, 2)]               0         \n",
            "_________________________________________________________________\n",
            "decoder_hidden_0 (Dense)     (None, 7)                 21        \n",
            "_________________________________________________________________\n",
            "decoder_hidden_1 (Dense)     (None, 15)                120       \n",
            "_________________________________________________________________\n",
            "decoder_output (Dense)       (None, 18)                288       \n",
            "=================================================================\n",
            "Total params: 429\n",
            "Trainable params: 429\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VJKrDgau_eu"
      },
      "source": [
        "def train(epoch, delta):\n",
        "    for i in range(epoch):\n",
        "        print('Global epoch: ' + str(i + 1) + '/' + str(epoch))      \n",
        "        \n",
        "        # 1. Send new version of the model\n",
        "        send_new_models(local_model, models)\n",
        "\n",
        "        # 2. Train remotely the models\n",
        "        for j, worker in enumerate(workers):\n",
        "\n",
        "            print('Training in ' + workers[j])\n",
        "            \n",
        "            models[j].train(in_train[j], in_test[j])\n",
        "\n",
        "        # 3. Federated aggregation of the updated models\n",
        "        federated_aggregation(local_model, models)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQHRbJKCimM5",
        "outputId": "f266a55a-03d5-4940-b2d2-ffcf5f7643ce"
      },
      "source": [
        "train(3, 1e-5)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:root:Training with data of shape (48639, 18)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Global epoch: 1/3\n",
            "Training in alice\n",
            "Epoch 1/14\n",
            "380/380 [==============================] - 4s 3ms/step - loss: 0.2195 - val_loss: 0.2112\n",
            "Epoch 2/14\n",
            "380/380 [==============================] - 1s 2ms/step - loss: 0.1757 - val_loss: 0.1410\n",
            "Epoch 3/14\n",
            "380/380 [==============================] - 1s 3ms/step - loss: 0.1270 - val_loss: 0.1060\n",
            "Epoch 4/14\n",
            "380/380 [==============================] - 1s 2ms/step - loss: 0.0965 - val_loss: 0.0436\n",
            "Epoch 5/14\n",
            "380/380 [==============================] - 1s 3ms/step - loss: 0.0591 - val_loss: 0.0377\n",
            "Epoch 6/14\n",
            "380/380 [==============================] - 1s 2ms/step - loss: 0.0574 - val_loss: 0.0347\n",
            "Epoch 7/14\n",
            "380/380 [==============================] - 1s 2ms/step - loss: 0.0570 - val_loss: 0.0392\n",
            "Epoch 8/14\n",
            "380/380 [==============================] - 1s 2ms/step - loss: 0.0542 - val_loss: 0.0385\n",
            "Epoch 9/14\n",
            "380/380 [==============================] - 1s 2ms/step - loss: 0.0627 - val_loss: 0.0493\n",
            "Epoch 10/14\n",
            "380/380 [==============================] - 1s 2ms/step - loss: 0.0628 - val_loss: 0.0525\n",
            "Epoch 11/14\n",
            "380/380 [==============================] - 1s 2ms/step - loss: 0.0552 - val_loss: 0.0288\n",
            "Epoch 12/14\n",
            "380/380 [==============================] - 1s 3ms/step - loss: 0.0536 - val_loss: 0.0304\n",
            "Epoch 13/14\n",
            "380/380 [==============================] - 1s 2ms/step - loss: 0.0561 - val_loss: 0.0356\n",
            "Epoch 14/14\n",
            "380/380 [==============================] - 1s 2ms/step - loss: 0.0549 - val_loss: 0.0305\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:root:Training with data of shape (48639, 18)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training in bob\n",
            "Epoch 1/14\n",
            "380/380 [==============================] - 4s 3ms/step - loss: 0.2195 - val_loss: 0.2110\n",
            "Epoch 2/14\n",
            "380/380 [==============================] - 1s 3ms/step - loss: 0.1755 - val_loss: 0.1403\n",
            "Epoch 3/14\n",
            "380/380 [==============================] - 1s 2ms/step - loss: 0.1267 - val_loss: 0.1047\n",
            "Epoch 4/14\n",
            "380/380 [==============================] - 1s 3ms/step - loss: 0.0963 - val_loss: 0.0422\n",
            "Epoch 5/14\n",
            "380/380 [==============================] - 1s 2ms/step - loss: 0.0589 - val_loss: 0.0361\n",
            "Epoch 6/14\n",
            "380/380 [==============================] - 1s 3ms/step - loss: 0.0572 - val_loss: 0.0331\n",
            "Epoch 7/14\n",
            "380/380 [==============================] - 1s 3ms/step - loss: 0.0568 - val_loss: 0.0374\n",
            "Epoch 8/14\n",
            "380/380 [==============================] - 1s 3ms/step - loss: 0.0541 - val_loss: 0.0367\n",
            "Epoch 9/14\n",
            "380/380 [==============================] - 1s 3ms/step - loss: 0.0627 - val_loss: 0.0476\n",
            "Epoch 10/14\n",
            "380/380 [==============================] - 1s 3ms/step - loss: 0.0627 - val_loss: 0.0508\n",
            "Epoch 11/14\n",
            "380/380 [==============================] - 1s 3ms/step - loss: 0.0551 - val_loss: 0.0270\n",
            "Epoch 12/14\n",
            "380/380 [==============================] - 1s 3ms/step - loss: 0.0534 - val_loss: 0.0283\n",
            "Epoch 13/14\n",
            "380/380 [==============================] - 1s 3ms/step - loss: 0.0560 - val_loss: 0.0335\n",
            "Epoch 14/14\n",
            "380/380 [==============================] - 1s 2ms/step - loss: 0.0547 - val_loss: 0.0285\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:root:Training with data of shape (48639, 18)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Global epoch: 2/3\n",
            "Training in alice\n",
            "Epoch 1/14\n",
            "380/380 [==============================] - 1s 3ms/step - loss: 0.0520 - val_loss: 0.0342\n",
            "Epoch 2/14\n",
            "380/380 [==============================] - 1s 3ms/step - loss: 0.0556 - val_loss: 0.0321\n",
            "Epoch 3/14\n",
            "380/380 [==============================] - 1s 3ms/step - loss: 0.0527 - val_loss: 0.0256\n",
            "Epoch 4/14\n",
            "380/380 [==============================] - 1s 3ms/step - loss: 0.0590 - val_loss: 0.0526\n",
            "Epoch 5/14\n",
            "380/380 [==============================] - 1s 3ms/step - loss: 0.0574 - val_loss: 0.0405\n",
            "Epoch 6/14\n",
            "380/380 [==============================] - 1s 2ms/step - loss: 0.0550 - val_loss: 0.0362\n",
            "Epoch 7/14\n",
            "380/380 [==============================] - 1s 2ms/step - loss: 0.0537 - val_loss: 0.0397\n",
            "Epoch 8/14\n",
            "380/380 [==============================] - 1s 3ms/step - loss: 0.0525 - val_loss: 0.0260\n",
            "Epoch 9/14\n",
            "380/380 [==============================] - 1s 3ms/step - loss: 0.0571 - val_loss: 0.0343\n",
            "Epoch 10/14\n",
            "380/380 [==============================] - 1s 3ms/step - loss: 0.0462 - val_loss: 0.0252\n",
            "Epoch 11/14\n",
            "380/380 [==============================] - 1s 3ms/step - loss: 0.0501 - val_loss: 0.0296\n",
            "Epoch 12/14\n",
            "380/380 [==============================] - 1s 3ms/step - loss: 0.0522 - val_loss: 0.0287\n",
            "Epoch 13/14\n",
            "380/380 [==============================] - 1s 3ms/step - loss: 0.0485 - val_loss: 0.0360\n",
            "Epoch 14/14\n",
            "380/380 [==============================] - 1s 3ms/step - loss: 0.0530 - val_loss: 0.0319\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:root:Training with data of shape (48639, 18)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training in bob\n",
            "Epoch 1/14\n",
            "380/380 [==============================] - 1s 3ms/step - loss: 0.0520 - val_loss: 0.0321\n",
            "Epoch 2/14\n",
            "380/380 [==============================] - 1s 3ms/step - loss: 0.0553 - val_loss: 0.0299\n",
            "Epoch 3/14\n",
            "380/380 [==============================] - 1s 3ms/step - loss: 0.0525 - val_loss: 0.0234\n",
            "Epoch 4/14\n",
            "380/380 [==============================] - 1s 3ms/step - loss: 0.0588 - val_loss: 0.0508\n",
            "Epoch 5/14\n",
            "380/380 [==============================] - 1s 2ms/step - loss: 0.0574 - val_loss: 0.0394\n",
            "Epoch 6/14\n",
            "380/380 [==============================] - 1s 3ms/step - loss: 0.0550 - val_loss: 0.0340\n",
            "Epoch 7/14\n",
            "380/380 [==============================] - 1s 3ms/step - loss: 0.0538 - val_loss: 0.0372\n",
            "Epoch 8/14\n",
            "380/380 [==============================] - 1s 3ms/step - loss: 0.0525 - val_loss: 0.0237\n",
            "Epoch 9/14\n",
            "380/380 [==============================] - 1s 3ms/step - loss: 0.0569 - val_loss: 0.0325\n",
            "Epoch 10/14\n",
            "380/380 [==============================] - 1s 3ms/step - loss: 0.0461 - val_loss: 0.0229\n",
            "Epoch 11/14\n",
            "380/380 [==============================] - 1s 3ms/step - loss: 0.0498 - val_loss: 0.0274\n",
            "Epoch 12/14\n",
            "380/380 [==============================] - 1s 2ms/step - loss: 0.0521 - val_loss: 0.0269\n",
            "Epoch 13/14\n",
            "380/380 [==============================] - 1s 3ms/step - loss: 0.0486 - val_loss: 0.0348\n",
            "Epoch 14/14\n",
            "380/380 [==============================] - 1s 2ms/step - loss: 0.0528 - val_loss: 0.0295\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:root:Training with data of shape (48639, 18)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Global epoch: 3/3\n",
            "Training in alice\n",
            "Epoch 1/14\n",
            "380/380 [==============================] - 1s 3ms/step - loss: 0.0502 - val_loss: 0.0386\n",
            "Epoch 2/14\n",
            "380/380 [==============================] - 1s 2ms/step - loss: 0.0563 - val_loss: 0.0415\n",
            "Epoch 3/14\n",
            "380/380 [==============================] - 1s 3ms/step - loss: 0.0571 - val_loss: 0.0366\n",
            "Epoch 4/14\n",
            "380/380 [==============================] - 1s 2ms/step - loss: 0.0585 - val_loss: 0.0320\n",
            "Epoch 5/14\n",
            "380/380 [==============================] - 1s 3ms/step - loss: 0.0547 - val_loss: 0.0371\n",
            "Epoch 6/14\n",
            "380/380 [==============================] - 1s 3ms/step - loss: 0.0520 - val_loss: 0.0271\n",
            "Epoch 7/14\n",
            "380/380 [==============================] - 1s 2ms/step - loss: 0.0517 - val_loss: 0.0297\n",
            "Epoch 8/14\n",
            "380/380 [==============================] - 1s 2ms/step - loss: 0.0530 - val_loss: 0.0368\n",
            "Epoch 9/14\n",
            "380/380 [==============================] - 1s 3ms/step - loss: 0.0513 - val_loss: 0.0320\n",
            "Epoch 10/14\n",
            "380/380 [==============================] - 1s 3ms/step - loss: 0.0519 - val_loss: 0.0261\n",
            "Epoch 11/14\n",
            "380/380 [==============================] - 1s 3ms/step - loss: 0.0528 - val_loss: 0.0358\n",
            "Epoch 12/14\n",
            "380/380 [==============================] - 1s 2ms/step - loss: 0.0568 - val_loss: 0.0372\n",
            "Epoch 13/14\n",
            "380/380 [==============================] - 1s 2ms/step - loss: 0.0535 - val_loss: 0.0313\n",
            "Epoch 14/14\n",
            "380/380 [==============================] - 1s 2ms/step - loss: 0.0580 - val_loss: 0.0353\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:root:Training with data of shape (48639, 18)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training in bob\n",
            "Epoch 1/14\n",
            "380/380 [==============================] - 1s 3ms/step - loss: 0.0502 - val_loss: 0.0362\n",
            "Epoch 2/14\n",
            "380/380 [==============================] - 1s 3ms/step - loss: 0.0562 - val_loss: 0.0396\n",
            "Epoch 3/14\n",
            "380/380 [==============================] - 1s 3ms/step - loss: 0.0571 - val_loss: 0.0341\n",
            "Epoch 4/14\n",
            "380/380 [==============================] - 1s 3ms/step - loss: 0.0590 - val_loss: 0.0302\n",
            "Epoch 5/14\n",
            "380/380 [==============================] - 1s 3ms/step - loss: 0.0544 - val_loss: 0.0361\n",
            "Epoch 6/14\n",
            "380/380 [==============================] - 1s 3ms/step - loss: 0.0517 - val_loss: 0.0250\n",
            "Epoch 7/14\n",
            "380/380 [==============================] - 1s 3ms/step - loss: 0.0508 - val_loss: 0.0265\n",
            "Epoch 8/14\n",
            "380/380 [==============================] - 1s 2ms/step - loss: 0.0558 - val_loss: 0.0455\n",
            "Epoch 9/14\n",
            "380/380 [==============================] - 1s 3ms/step - loss: 0.0543 - val_loss: 0.0259\n",
            "Epoch 10/14\n",
            "380/380 [==============================] - 1s 2ms/step - loss: 0.0533 - val_loss: 0.0258\n",
            "Epoch 11/14\n",
            "380/380 [==============================] - 1s 3ms/step - loss: 0.0524 - val_loss: 0.0324\n",
            "Epoch 12/14\n",
            "380/380 [==============================] - 1s 3ms/step - loss: 0.0566 - val_loss: 0.0376\n",
            "Epoch 13/14\n",
            "380/380 [==============================] - 1s 3ms/step - loss: 0.0540 - val_loss: 0.0301\n",
            "Epoch 14/14\n",
            "380/380 [==============================] - 1s 3ms/step - loss: 0.0584 - val_loss: 0.0330\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssHsGbZc-qCs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98eb1bc0-fd58-4f30-ba8b-b83daa541c63"
      },
      "source": [
        "inlier_scores = local_model.compute_anomaly_score(save_in_test)\n",
        "outlier_scores = local_model.compute_anomaly_score(out_test)\n",
        "print(inlier_scores)\n",
        "print(outlier_scores)\n",
        "metrics = eval_utils.evaluate_model(\n",
        "    inlier_scores, outlier_scores, model_name=\"ae\", show_plot=False)\n",
        "print(metrics)\n",
        "local_model.save_model()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:root:4686unique thresholds\n",
            "INFO:root:Testing all thresholds to find best accuracy ...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[4.68310857e-01 5.09136240e-01 1.00915558e-04 ... 1.09394045e-01\n",
            " 1.03862758e-01 5.18827232e-02]\n",
            "[0.38385925 0.14143097 0.14143097 ... 0.05893645 0.05921918 0.14143097]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:root:Threshold testing complete ...\n",
            "INFO:root:Best accuracy is .. {'acc': 0.9314, 'threshold': 0.14}\n",
            "INFO:root:>> Saving AE model to models/savedmodels/ae/\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'acc': 0.9311, 'precision': 0.823065549531789, 'recall': 0.835, 'f1': 0.8289898237776122, 'f2': 0.8325855020440722, 'roc': 0.9383488749999999, 'threshold': 0.14}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}